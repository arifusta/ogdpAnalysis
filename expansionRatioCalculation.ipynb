{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "822409e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pymongo import MongoClient\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "from dataclasses import dataclass\n",
    "from tqdm import tqdm\n",
    "import uuid\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fb76a3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_FILES_PATH = \"D:\\\\all_files\"\n",
    "if(not os.path.exists(ALL_FILES_PATH)):\n",
    "    raise Exception(\"ALL_FILES_PATH does not exist\")\n",
    "NUM_PROCESSES = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c539f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3964795\n"
     ]
    }
   ],
   "source": [
    "with open('JPairs_n10_90_ALL.pickle', 'rb') as handle:\n",
    "    jPairs = pickle.load(handle)\n",
    "print(len(jPairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f6e253c",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient('mongodb://admin:V6jjpnR8Ee8NuxdgYsrqsfWBRaQ4yWFQKbc8teM4eYXUYJJTRZ@direct.montreal-1.mew.im:27777'\n",
    "                     '/?authSource=admin&readPreference=primary&directConnection=true&ssl=false')\n",
    "repoNames = ['Singapore', 'Canada', 'UK', 'US']\n",
    "mongoCollections = []\n",
    "\n",
    "mongoCollections.append(client['datagovsg'])\n",
    "mongoCollections.append(client['opencanada'])\n",
    "mongoCollections.append(client['datagovuk'])\n",
    "mongoCollections.append(client['datagov'])\n",
    "\n",
    "tableStats = []\n",
    "for collect in mongoCollections:\n",
    "    tableStats.append(collect['inferredstats'])\n",
    "tableDocs = []\n",
    "for portal in tableStats:\n",
    "    for table_doc in portal.find({}, {\"_id\": 0, \"schema\": 0}):\n",
    "        tableDocs.append(table_doc)\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6c56adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "allUUIDs = set()\n",
    "for j in jPairs:\n",
    "    allUUIDs.add(j['leftTableID'])\n",
    "    allUUIDs.add(j['rightTableID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fbfff7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tableDocs = [x for x in tableDocs if x['uuid'] in allUUIDs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6284eb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readCSV(table_doc):\n",
    "    csvID = table_doc['uuid']\n",
    "    encoding = table_doc['encoding']\n",
    "    header = table_doc['header']\n",
    "    delimiter = table_doc['delimiter'] if 'delimiter' in table_doc else ','\n",
    "    file_path = os.path.join(ALL_FILES_PATH, csvID + '.csv')\n",
    "    print(file_path)\n",
    "    if header == 0:\n",
    "        df = pd.read_csv(file_path, low_memory=False, encoding=encoding, delimiter=delimiter)\n",
    "    else:\n",
    "        df = pd.read_csv(file_path, skiprows=header, low_memory=False, encoding=encoding, delimiter=delimiter)\n",
    "        df.drop(df.filter(regex=\"Unnamed\"),axis=1, inplace=True)\n",
    "        df.dropna(how='all', inplace= True)\n",
    "    df.columns = list(range(0, df.shape[1]))\n",
    "    return {\"uuid\": csvID, \"df\": df}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "550a2d17",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Pool' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m tables_map \u001b[39m=\u001b[39m {}\n\u001b[1;32m----> 2\u001b[0m \u001b[39mwith\u001b[39;00m Pool(processes\u001b[39m=\u001b[39mNUM_PROCESSES) \u001b[39mas\u001b[39;00m pool:\n\u001b[0;32m      3\u001b[0m     \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m tqdm(pool\u001b[39m.\u001b[39mimap_unordered(readCSV, tableDocs), total\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(tableDocs)):\n\u001b[0;32m      4\u001b[0m         tables_map[data[\u001b[39m'\u001b[39m\u001b[39muuid\u001b[39m\u001b[39m'\u001b[39m]] \u001b[39m=\u001b[39m data[\u001b[39m'\u001b[39m\u001b[39mdf\u001b[39m\u001b[39m'\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Pool' is not defined"
     ]
    }
   ],
   "source": [
    "tables_map = {}\n",
    "with Pool(processes=NUM_PROCESSES) as pool:\n",
    "    for data in tqdm(pool.imap_unordered(readCSV, tableDocs), total=len(tableDocs)):\n",
    "        tables_map[data['uuid']] = data['df']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf7e146",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4e25117e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\all_files\\205f7050-39fd-4af3-899b-ac2dd323e437.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'uuid': '205f7050-39fd-4af3-899b-ac2dd323e437',\n",
       " 'df':        0    1    2\n",
       " 0   1990  4.5  4.0\n",
       " 1   1991  3.9  3.5\n",
       " 2   1992  3.7  3.3\n",
       " 3   1993  3.6  3.1\n",
       " 4   1994  3.5  3.1\n",
       " 5   1995  3.5  3.0\n",
       " 6   1996  3.2  2.8\n",
       " 7   1997  3.2  2.7\n",
       " 8   1998  2.3  2.1\n",
       " 9   1999  2.6  2.2\n",
       " 10  2000  3.2  2.5\n",
       " 11  2001  2.5  2.2\n",
       " 12  2002  2.4  2.1\n",
       " 13  2003  2.3  2.0\n",
       " 14  2004  2.8  2.2\n",
       " 15  2005  2.7  2.1\n",
       " 16  2006  2.8  2.0\n",
       " 17  2007  2.9  2.0\n",
       " 18  2008  2.8  2.0\n",
       " 19  2009  2.2  1.8\n",
       " 20  2010  2.8  2.0\n",
       " 21  2011  2.7  2.0\n",
       " 22  2012  2.8  2.1\n",
       " 23  2013  2.7  2.0\n",
       " 24  2014  2.6  2.0\n",
       " 25  2015  2.4  1.9\n",
       " 26  2016  2.2  1.8\n",
       " 27  2017  2.1  1.8\n",
       " 28  2018  2.3  1.8\n",
       " 29  2019  2.2  1.8\n",
       " 30  2020  1.6  1.5}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "readCSV(tableDocs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335c8605",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_columns(pair):\n",
    "    import duckdb\n",
    "    duckdb.query(\"PRAGMA threads=2;\")\n",
    "    view_name = \"view_\" + str(uuid.uuid1().hex)\n",
    "    portal = pair['portal']\n",
    "    \n",
    "    #pair = j['pair']\n",
    "    try:\n",
    "        if portal == 'SG':\n",
    "            table_1 = readCSVFromZipSG(pair['leftTableDoc'])['df']\n",
    "            table_1.columns = list(range(0, table_1.shape[1]))\n",
    "            table_2 = readCSVFromZipSG(pair['rightTableDoc'])['df']\n",
    "            table_2.columns = list(range(0, table_2.shape[1]))\n",
    "        elif portal == 'CA':\n",
    "            table_1 = readCSVFromZipCA(pair['leftTableDoc'])['df']\n",
    "            table_1.columns = list(range(0, table_1.shape[1]))\n",
    "            table_2 = readCSVFromZipCA(pair['rightTableDoc'])['df']\n",
    "            table_2.columns = list(range(0, table_2.shape[1]))\n",
    "        elif portal == 'UK':\n",
    "            table_1 = readCSVFromZipUK(pair['leftTableDoc'])['df']\n",
    "            table_1.columns = list(range(0, table_1.shape[1]))\n",
    "            table_2 = readCSVFromZipUK(pair['rightTableDoc'])['df']\n",
    "            table_2.columns = list(range(0, table_2.shape[1]))\n",
    "        elif portal == 'US':\n",
    "            table_1 = readCSVFromZipUS(pair['leftTableDoc'])['df']\n",
    "            table_1.columns = list(range(0, table_1.shape[1]))\n",
    "            table_2 = readCSVFromZipUS(pair['rightTableDoc'])['df']\n",
    "            table_2.columns = list(range(0, table_2.shape[1]))\n",
    "            \n",
    "        query_string = 'CREATE VIEW %s AS\\\n",
    "            (\\\n",
    "                WITH T1 AS (SELECT \"%d\" AS col_1, COUNT(*) AS count_1 FROM table_1 GROUP BY \"%d\"),\\\n",
    "                    T2 AS (SELECT \"%d\" AS col_2, COUNT(*) AS count_2 FROM table_2 GROUP BY \"%d\")\\\n",
    "                    SELECT *, (count_1 * count_2) AS total_count FROM T1 INNER JOIN  T2 ON T1.col_1 = T2.col_2\\\n",
    "            )' % (view_name, pair['leftColumnIndex'], pair['leftColumnIndex'], pair['rightColumnIndex'], pair['rightColumnIndex'])\n",
    "\n",
    "        duckdb.query(query_string)\n",
    "        joined_count_result = duckdb.query('SELECT SUM(total_count) AS aggregated FROM %s' % view_name).to_df()\n",
    "        joined_count = int(joined_count_result['aggregated'][0])\n",
    "\n",
    "        cardinality = \"one:one\"\n",
    "        is_many_many_result = duckdb.query(\n",
    "            'SELECT * FROM %s WHERE count_1 > 1 AND count_2 > 1 LIMIT 1' % view_name).to_df()\n",
    "        if len(is_many_many_result) > 0:\n",
    "            cardinality = \"many:many\"\n",
    "        else:\n",
    "            is_many_one_result = duckdb.query(\n",
    "                'SELECT * FROM %s WHERE (count_1 > 1 AND count_2 = 1) OR (count_1 = 1 AND count_2 > 1) LIMIT 1' % view_name).to_df()\n",
    "            if len(is_many_one_result) > 0:\n",
    "                cardinality = \"many:one\"\n",
    "        duckdb.query('DROP VIEW IF EXISTS %s' % view_name)\n",
    "        return {\n",
    "            'pair': pair,\n",
    "            'score' : pair['score'],\n",
    "            'cardinality': cardinality,\n",
    "            'joined_count': joined_count,\n",
    "            'expRatio' : joined_count / max(table_1.shape[0], table_2.shape[0])\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return {\n",
    "            'pair': pair\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba3273d",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_pairs = []\n",
    "results = []\n",
    "\n",
    "for pair in tqdm(jPairs[0:100], total=100):\n",
    "\n",
    "    #print (joinablePair) \n",
    "    data = compare_columns(pair)\n",
    "    if 'cardinality' in data:\n",
    "        results.append(data)\n",
    "    else:\n",
    "        error_pairs.append(data['pair'])\n",
    "        #break\n",
    "print(len(results))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1d79add",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing pairs has started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███████▉                                                                       | 100/1000 [00:04<00:41, 21.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 3964795 pairs is done.\n",
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from decompositionJoin import *\n",
    "if __name__ == '__main__':\n",
    "    error_pairs = []\n",
    "    results = []\n",
    "    NUM_PROCESSES = 4 # Chang do not forget to change here\n",
    "    print('Processing pairs has started.')\n",
    "    with Pool(processes=NUM_PROCESSES) as pool:\n",
    "        for data in tqdm(pool.imap_unordered(compare_columns, jPairs[0:100]), total=1000):\n",
    "            if 'cardinality' in data:\n",
    "                results.append(data)\n",
    "            else:\n",
    "                error_pairs.append(data['pair'])\n",
    "\n",
    "    print(f'Processing {len(jPairs)} pairs is done.')\n",
    "print(len(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f6cf61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "c261aea317cc0286b3b3261fbba9abdec21eaa57589985bb7a274bf54d6cc0a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
